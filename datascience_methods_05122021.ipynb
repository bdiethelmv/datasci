{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date: May 12 2021\n",
    "## Author: Benjamin Diethelm-Varela\n",
    "## Data Science methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science methodology\n",
    "Methodology is a system of methods used in a particular area of study\n",
    "\n",
    "## Standard methodology\n",
    "In data science, the standard methodology involves a stepwise approach, with 10 well-defined steps:\n",
    "\n",
    "1) Define the problem (business understanding)\n",
    "2) Define how data can solve the problem (analytic approach)\n",
    "3) Identify what data needs to be gathered (data requirements)\n",
    "4) Identify the likely sources of data and how it will be acquired (data collection)\n",
    "5) Identify whether the collected data is representative of the problem (data understanding)\n",
    "6) Define work that needs to be done towards data manipulation (data preparation)\n",
    "7) Define which visualizations are most appropriate and create your models (modeling)\n",
    "8) Assess whether the model answers the question (evaluation)\n",
    "9) Assess whether the model works in practice at the larger world (deployment\n",
    "10) Seek constructive feedback (feedback)\n",
    "\n",
    "Steps 1-2 involve identifyng the problem and the approach. Steps 3-6 pertain to data work. Steps 7-10 involve implementing the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CRIPS-DM methodology\n",
    "Another widely used methodology for data science in industry is the Cross Industry Process for Data Mining (CRISP-DM). This involves six steps:\n",
    "1. Business understanding: what the business wants and needs\n",
    "2. Data understanding: what data is gathered according to the business' needs\n",
    "3. Data preparation\n",
    "4. Modeling: the idea of a model is to give insights and expand knowledge\n",
    "5. Evaluation: typically a pre-selected test is run on the model\n",
    "6. Deployment: the model is used on new datasets and by new stakeholders. New challenges might prompt revisions\n",
    "\n",
    "This methodology is cyclic and requires high flexibility at every step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding\n",
    "Business understanding refers to attaining clarification: knowing what is the problem that is meant to be solved.\n",
    "We need to understand the goal of the person or entity asking the question.\n",
    "\n",
    "Example: how to allocate healthcare budget to maximize its use in attaining better health outcomes. Data science can be used to create an algorithm to identify inefficiencies and work on them, such as a decision tree. It is important that models predict outcomes, predict risk, understand variables determining risk, and communicate this understanding efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic approach\n",
    "The approach depends on the question being asked. Once the problem to be addressed is properly understood, we need a proper analytic approach.\n",
    "\n",
    "There are several approaches available:\n",
    "\n",
    "- Predictive model: to show probabilities of an event\n",
    "- Descriptive model: to show relationships\n",
    "- Classification model: to give a yes/no answer to a question\n",
    "\n",
    "Questions requiring counts call for statistical analysis, specifically regression models. Questions regarding category definition call for classification models.\n",
    "\n",
    "Machine learning models offer identification of trends which might be otherwise unidentifiable\n",
    "\n",
    "Example: to identify risk groups in cardiovascular patients, a decision tree model was developed\n",
    "\n",
    "### Decision trees\n",
    "Decision trees are a common type of classifier model. They separate data into categories. An ideal decision tree ends up with completely pure leaf nodes\n",
    "They are easy to interpret, work well with both numeric and categorical variables, and handle missing data well. However, they tend to both overfit and underfit if parameters are not tweaked carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Requirements\n",
    "After deciding on the analytic approach, it is critical to identify the data that must be gathered, how to gather it, and how to treat it. \n",
    "\n",
    "Example: in a clinical study, the data requirement stage will involve selecting and enrolling a suitable cohort, which meets a set of criteria. Thinking ahead and identifying challenges with the data preparation stage usually pays off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "When collecting the data, it is important to decide and revise on how to proceed as the data is being collected. For example, if the data proves to be insufficient on some respect, more data collection may be necessary. This is a back-and-forth process with data requirements; requirements are updated depending on the quality and quantity of data acquired.\n",
    "It is ok to defer decisions about unavailable data and decide at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding\n",
    "All activities related to constructing the data set. It must answer the question: is the collected data representative of the problem being solved.\n",
    "In many datasets, descriptive statistics will be used, including univariate statistics, pairwise correlations, and visualizations such as histograms. Histograms are particularly useful in getting a good glimpse of how data are distributed, and so decide what treatment is most appropriate.\n",
    "Statistics are also used to assess data quality. Sometimes statistics allows for the removal of missing/misleading values or variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "This involves cleansing the data to remove errors and imperfections. This is the most time-consuming step. Automation is crucial here if efficiency is a priority.\n",
    "This step answers the question of what are the ways data must be prepared?\n",
    "Feature engineering is also done at this stage. It involves creating tools for machine learning algorithms to work.\n",
    "Text analysis is a common challenge, and requires strong programming to detect patterns.\n",
    "If done right, the data will be up to scratch to answer the project questions.\n",
    "As an example, when doing a clinical study, multiple sources of a patient's clinical data must be consolidated into a single record which will be used for an ML algorithm, such as a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Modeling is the stage where the cleansed data is used to build a model and make initial predictions. The results of those predictions will inform whether extra data work is needed, at any of the previous stages. Crucially, we must answer whether the new model can address the original question\n",
    "\n",
    "Models are either descriptive (show a relationship) or predictive (predict an outcome).\n",
    "\n",
    "Models can either be statistically driven or machine learning driven. A training set is used to build the model, and a test set to evaluate its success.\n",
    "\n",
    "Constant refining is needed. This ensures the field of data science proves it's relevant.\n",
    "\n",
    "Models are often assessed in terms of their accuracy. Specifically, we want to watch out for 2 types of errors:\n",
    "\n",
    "- Type 1 error: a false positive; the model predicts the \"yes\" answer when a \"no\" had happened in reality\n",
    "- Type 2 error: a false negative; the model predicts the \"no\" answer, failing to detect an underlying \"yes\"\n",
    "\n",
    "Sensitivity (true positive rate) is accuracy for the yes answer. High sensitivity prevents false negatives. This metric is especially important in cancer diagnostic tools (true positives/(true positives+false negatives))\n",
    "\n",
    "Specificity (true negative rate) is accuracy for the no answer. High specificity prevents false positives (true negatives/(true negatives+false positives)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Modeling and evaluation happen hand in hand. Evaluation answers whether the model addresses the initial question.\n",
    "In descriptive statistics, statistical significance is common for evaluation.\n",
    "\n",
    "For a predictive model, an ROC curve (receiving operating characteristic) is typically used. It plots the true positive rate (sensitivity) vs the false positive rate (specificity). An ideal model would be located at the upper left corner (i.e. TP rate of 1, FP rate of 0)\n",
    "\n",
    "Models are often evaluated splitting the data into a train set and a test set. Since the model is not exposed to the test data, it serves as a valid way of seeing how well it makes predictions on new information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "The stakeholders should get familiar with the tool produced. The tool should be made available to the relevant personnel as part as an easy-to-use, easy-to-understand solution. Creating a simple GUI with well summarized information is vital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "Feedback from users will help refine the model and incorporate improvements; the more you know, the more you want to know.\n",
    "Compare outcomes before and after the implementation of the model. Incorporate data which may have gone neglected during the first modeling process. Model will be reviewed, refined, and redeployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science methodology in a nutshell\n",
    "Business understanding - Analytic approach - Data requirements - Data collection - Data understanding - Data preparation - Modeling - Evaluation - Deployment - Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
